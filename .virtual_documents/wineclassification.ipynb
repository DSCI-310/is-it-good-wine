import altair as alt
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

from sklearn.model_selection import cross_val_score, cross_validate, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import RepeatedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report
from sklearn.dummy import DummyClassifier
from IPython import display


df = pd.read_csv('data/winequality-red.csv', sep=',') # UCI Machine Learning Database


x = alt.Chart(df).mark_bar().encode(
    alt.X('quality:O'),
    alt.Y('count()')
).properties(
    width=200,
    height=100
)

x


cor_data = (df.corr()
            .stack()
            .reset_index()     # The stacking results in an index on the correlation values, we need the index as normal columns for Altair
            .rename(columns={0: 'correlation', 'level_0': 'variable1', 'level_1': 'variable2'}))
cor_data['correlation_label'] = cor_data['correlation'].map('{:.2f}'.format)  # Round to 2 decimal


# This is the inter-related correlations of each chemical ingredient
# Judging on the correlations we may be able to infer coefficient signage.

alt.Chart(cor_data).mark_rect().encode(
    alt.X('variable1:O'),
    alt.Y('variable2:O'),
    alt.Color('correlation'),
    alt.Tooltip(['correlation_label']),
).interactive().properties(width=300, height=300)


train_df, test_df = train_test_split(df, test_size=0.30, random_state=123)
train_df['target'] = np.where(train_df['quality'] > 5, 1, 0)
test_df['target'] = np.where(test_df['quality'] > 5, 1, 0)
train_df.head()


# Checking for class imbalance
train_df["target"].value_counts()


# Splitting into X and y train and test sets
X_train = train_df.drop(columns=["target", "quality"])
y_train = train_df["target"]

X_test = test_df.drop(columns=["target", "quality"])
y_test = test_df["target"]


baseline = DummyClassifier(strategy = 'most_frequent')

baseline.fit(X_train, y_train)
baseline.predict(X_test)

basescore = baseline.score(X_test, y_test)
print("The accuracy of the baseline model is:", basescore)


scores_dict = {
    "C": 10.0 ** np.arange(-4, 6, 1),
    "mean_train_scores": list(),
    "mean_cv_scores": list(),
}
for C in scores_dict["C"]:
    pipe = make_pipeline(StandardScaler(), LogisticRegression(C = C, random_state = 1234))
    scores = cross_validate(pipe, X_train, y_train, return_train_score=True)
    scores_dict["mean_train_scores"].append(scores["train_score"].mean())
    scores_dict["mean_cv_scores"].append(scores["test_score"].mean())

results_df = pd.DataFrame(scores_dict)
results_df


# Scaling and applying LogisticRegression model to our data
pipe = make_pipeline(StandardScaler(), LogisticRegression(C = 0.01, class_weight = 'balanced', random_state = 1234))
pipe.fit(X_train, y_train)


# Printing out coefficients of the regression model for values influencing the model.
flatten = pipe.named_steps["logisticregression"].coef_ # 2-D Array
flatten = flatten.flatten() # Converting 2-D Array to 1-D Array

coeffs = pd.DataFrame(
    data={
        "features": X_train.columns, # 1-D Array
        "coefficients": flatten, # 1-D Array
    })

intercept = pipe.named_steps["logisticregression"].intercept_

print(coeffs.sort_values('coefficients', ascending = False))
print(f"The intercept is: {intercept}")


# Let's try categorizing a random wine sample!
lrscore = pipe.score(X_test, y_test)
print(lrscore)


ax = pd.DataFrame(data = {'actual': y_test,
                          'predicted': pipe.predict(X_test)})
ax['correct'] = ax['actual'] == ax['predicted']
print(ax.correct.value_counts())


print(classification_report(y_test, pipe.predict(X_test)))


# Hyperparameter optimization on 'C' and 'gamma'

best_score = 0

param_grid = {
    "C": [0.001, 0.01, 0.1, 1, 10, 100],
    "gamma": [0.001, 0.01, 0.1, 1, 10, 100],
}

for gamma in param_grid["gamma"]:
    for C in param_grid["C"]:
        pipe_svc = make_pipeline(StandardScaler(), SVC(gamma=gamma, C=C, class_weight='balanced', random_state = 1234))
        scores = cross_val_score(pipe_svc, X_train, y_train, cv=5) 
        mean_score = np.mean(scores)
        if (mean_score > best_score):
            best_score = mean_score
            best_parameters = {"C": C, "gamma": gamma}

print(best_parameters, ", best_score:", best_score)


# Instantiate the pipeline with a scaler and the SVM RBF Classifier

pipe_svm = make_pipeline(StandardScaler(), SVC(**best_parameters, class_weight='balanced', random_state = 1234))
pipe_svm.fit(
    X_train, y_train
)


svcscore = pipe_svm.score(X_test, y_test)
print(svcscore)


# True/False Ratio

svc = pd.DataFrame(data = {'actual': y_test,
                          'predicted': pipe_svm.predict(X_test)})
svc['correct'] = svc['actual'] == svc['predicted']
svc.correct.value_counts()


print(classification_report(y_test, pipe_svm.predict(X_test)))


X_train.head()


best_score = 0

param_grid = {"max_depth": np.arange(1, 20, 2)}

results_dict = {"max_depth": [], "mean_cv_score": []}
for depth in param_grid["max_depth"]:
    dtc = DecisionTreeClassifier(max_depth=depth, class_weight='balanced')
    scores = cross_val_score(dtc, X_train, y_train)
    mean_score = np.mean(scores) 

    if (mean_score > best_score):
        best_score = mean_score
        best_params = {"max_depth": depth}

    results_dict["max_depth"].append(depth)
    results_dict["mean_cv_score"].append(mean_score)

results_df = pd.DataFrame(results_dict)
results_df


clf = DecisionTreeClassifier(max_depth = 7, random_state=1234, class_weight='balanced')
model = clf.fit(X_train, y_train)

clf2 = DecisionTreeClassifier(max_depth = 3, random_state=1234, class_weight='balanced')
model2 = clf2.fit(X_train, y_train)

fig = plt.figure(figsize=(15,5))
_ = plot_tree(clf2, 
                   feature_names=X_train.columns,  
                   class_names= 'target',
                   filled=True, fontsize = 7)


dtscore = model.score(X_test, y_test)
print(dtscore)


dt = pd.DataFrame(data = {'actual': y_test,
                          'predicted': model.predict(X_test)})
dt['correct'] = dt['actual'] == dt['predicted']
dt.correct.value_counts()


#Import Gaussian Naive Bayes model
from sklearn.naive_bayes import GaussianNB

#Create a Gaussian Classifier
bayes = GaussianNB()
bayes.fit(X_train, y_train)


nbscore = bayes.score(X_test, y_test)
print(nbscore)


naive = pd.DataFrame(data = {'actual': y_test,
                          'predicted': bayes.predict(X_test)})
naive['correct'] = naive['actual'] == naive['predicted']
naive.correct.value_counts()


cscores = [basescore, lrscore, svcscore, dtscore, nbscore]

report = pd.DataFrame()
report = report.append(pd.DataFrame([cscores], 
     columns=['Baseline', 'LR', 'SVC', 'DT', 'NB']), 
     ignore_index = True)

report.index = ['Score']
report = report.T.reset_index()


y = alt.Chart(report).mark_bar().encode(
    alt.X('Score:Q'),
    alt.Y('index:N'),
    color=alt.condition(
    alt.datum.Score == max(report['Score']),  # If the year is 1810 this test returns True,
    alt.value('red'),     # which sets the bar orange.
    alt.value('steelblue')   # And if it's not true it sets the bar steelblue.
    )
).properties(
    width=500,
    height=200
).configure(
    background='lightgrey'
)

y
